{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56a2e6c1-e045-4f7a-b8c8-db0d297cd23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before cleaning:\n",
      " product_id          0\n",
      "actual_price        0\n",
      "discounted_price    0\n",
      "rating              0\n",
      "rating_count        2\n",
      "dtype: int64\n",
      "Cleaned Data Sample:\n",
      "    product_id                                       product_name  \\\n",
      "0  B07JW9H4J1  Wayona Nylon Braided USB to Lightning Fast Cha...   \n",
      "1  B098NS6PVG  Ambrane Unbreakable 60W / 3A Fast Charging 1.5...   \n",
      "2  B096MSW6CT  Sounce Fast Phone Charging Cable & Data Sync U...   \n",
      "3  B08HDJ86NZ  boAt Deuce USB 300 2 in 1 Type-C & Micro USB S...   \n",
      "4  B08CF3B7N1  Portronics Konnect L 1.2M Fast Charging 3A 8 P...   \n",
      "\n",
      "                                            category  discounted_price  \\\n",
      "0  Computers&Accessories|Accessories&Peripherals|...         -0.393080   \n",
      "1  Computers&Accessories|Accessories&Peripherals|...         -0.421875   \n",
      "2  Computers&Accessories|Accessories&Peripherals|...         -0.421875   \n",
      "3  Computers&Accessories|Accessories&Peripherals|...         -0.403158   \n",
      "4  Computers&Accessories|Accessories&Peripherals|...         -0.428353   \n",
      "\n",
      "   actual_price discount_percentage    rating  rating_count  \\\n",
      "0     -0.400106                 64%  0.357004      0.139765   \n",
      "1     -0.469057                 43% -0.334322      0.601285   \n",
      "2     -0.326558                 90% -0.679985     -0.242577   \n",
      "3     -0.436879                 53%  0.357004      1.779803   \n",
      "4     -0.464460                 61%  0.357004     -0.032535   \n",
      "\n",
      "                                       about_product  \\\n",
      "0  High Compatibility : Compatible With iPhone 12...   \n",
      "1  Compatible with all Type C enabled devices, be...   \n",
      "2  【 Fast Charger& Data Sync】-With built-in safet...   \n",
      "3  The boAt Deuce USB 300 2 in 1 cable is compati...   \n",
      "4  [CHARGE & SYNC FUNCTION]- This cable comes wit...   \n",
      "\n",
      "                                             user_id  \\\n",
      "0  AG3D6O4STAQKAY2UVGEUV46KN35Q,AHMY5CWJMMK5BJRBB...   \n",
      "1  AECPFYFQVRUWC3KGNLJIOREFP5LQ,AGYYVPDD7YG7FYNBX...   \n",
      "2  AGU3BBQ2V2DDAMOAKGFAWDDQ6QHA,AESFLDV2PT363T2AQ...   \n",
      "3  AEWAZDZZJLQUYVOVGBEUKSLXHQ5A,AG5HTSFRRE6NL3M5S...   \n",
      "4  AE3Q6KSUK5P75D5HFYHCRAOLODSA,AFUGIFH5ZAFXRDSZH...   \n",
      "\n",
      "                                           user_name  \\\n",
      "0  Manav,Adarsh gupta,Sundeep,S.Sayeed Ahmed,jasp...   \n",
      "1  ArdKn,Nirbhay kumar,Sagar Viswanathan,Asp,Plac...   \n",
      "2  Kunal,Himanshu,viswanath,sai niharka,saqib mal...   \n",
      "3  Omkar dhale,JD,HEMALATHA,Ajwadh a.,amar singh ...   \n",
      "4  rahuls6099,Swasat Borah,Ajay Wadke,Pranali,RVK...   \n",
      "\n",
      "                                           review_id  \\\n",
      "0  R3HXWT0LRP0NMF,R2AJM3LFTLZHFO,R6AQJGUP6P86,R1K...   \n",
      "1  RGIQEG07R9HS2,R1SMWZQ86XIN8U,R2J3Y1WL29GWDE,RY...   \n",
      "2  R3J3EQQ9TZI5ZJ,R3E7WBGK7ID0KV,RWU79XKQ6I1QF,R2...   \n",
      "3  R3EEUZKKK9J36I,R3HJVYCLYOY554,REDECAZ7AMPQC,R1...   \n",
      "4  R1BP4L2HH9TFUP,R16PVJEXKV6QZS,R2UPDB81N66T4P,R...   \n",
      "\n",
      "                                        review_title  \\\n",
      "0  Satisfied,Charging is really fast,Value for mo...   \n",
      "1  A Good Braided Cable for Your Type C Device,Go...   \n",
      "2  Good speed for earlier versions,Good Product,W...   \n",
      "3  Good product,Good one,Nice,Really nice product...   \n",
      "4  As good as original,Decent,Good one for second...   \n",
      "\n",
      "                                      review_content  \\\n",
      "0  Looks durable Charging is fine tooNo complains...   \n",
      "1  I ordered this cable to connect my phone to An...   \n",
      "2  Not quite durable and sturdy,https://m.media-a...   \n",
      "3  Good product,long wire,Charges good,Nice,I bou...   \n",
      "4  Bought this instead of original apple, does th...   \n",
      "\n",
      "                                            img_link  \\\n",
      "0  https://m.media-amazon.com/images/W/WEBP_40237...   \n",
      "1  https://m.media-amazon.com/images/W/WEBP_40237...   \n",
      "2  https://m.media-amazon.com/images/W/WEBP_40237...   \n",
      "3  https://m.media-amazon.com/images/I/41V5FtEWPk...   \n",
      "4  https://m.media-amazon.com/images/W/WEBP_40237...   \n",
      "\n",
      "                                        product_link          main_category  \\\n",
      "0  https://www.amazon.in/Wayona-Braided-WN3LG1-Sy...  Computers&Accessories   \n",
      "1  https://www.amazon.in/Ambrane-Unbreakable-Char...  Computers&Accessories   \n",
      "2  https://www.amazon.in/Sounce-iPhone-Charging-C...  Computers&Accessories   \n",
      "3  https://www.amazon.in/Deuce-300-Resistant-Tang...  Computers&Accessories   \n",
      "4  https://www.amazon.in/Portronics-Konnect-POR-1...  Computers&Accessories   \n",
      "\n",
      "   main_category_encoded  \n",
      "0                      1  \n",
      "1                      1  \n",
      "2                      1  \n",
      "3                      1  \n",
      "4                      1  \n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.64      0.62       134\n",
      "           2       0.65      0.66      0.65       152\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.57      0.53      0.55       142\n",
      "           5       0.00      0.00      0.00         0\n",
      "           7       0.50      0.40      0.44        10\n",
      "\n",
      "    accuracy                           0.60       439\n",
      "   macro avg       0.39      0.37      0.38       439\n",
      "weighted avg       0.60      0.60      0.60       439\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nigam\\AppData\\Local\\Temp\\ipykernel_8064\\829510698.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['actual_price'] = df_cleaned['actual_price'].str.replace('₹', '').str.replace(',', '').astype(float)\n",
      "C:\\Users\\Nigam\\AppData\\Local\\Temp\\ipykernel_8064\\829510698.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['discounted_price'] = df_cleaned['discounted_price'].str.replace('₹', '').str.replace(',', '').astype(float)\n",
      "C:\\Users\\Nigam\\AppData\\Local\\Temp\\ipykernel_8064\\829510698.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['rating'] = pd.to_numeric(df_cleaned['rating'], errors='coerce')\n",
      "C:\\Users\\Nigam\\AppData\\Local\\Temp\\ipykernel_8064\\829510698.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['rating_count'] = df_cleaned['rating_count'].str.replace(',', '').astype(float)\n",
      "C:\\Users\\Nigam\\AppData\\Local\\Temp\\ipykernel_8064\\829510698.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['rating'] = imputer.fit_transform(df_cleaned[['rating']])\n",
      "C:\\Users\\Nigam\\AppData\\Local\\Temp\\ipykernel_8064\\829510698.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[numerical_columns] = scaler.fit_transform(df_cleaned[numerical_columns])\n",
      "C:\\Users\\Nigam\\AppData\\Local\\Temp\\ipykernel_8064\\829510698.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['main_category'] = df_cleaned['category'].str.split('|').str[0]\n",
      "C:\\Users\\Nigam\\AppData\\Local\\Temp\\ipykernel_8064\\829510698.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['main_category_encoded'] = encoder.fit_transform(df_cleaned['main_category'])\n",
      "C:\\Users\\Nigam\\AppData\\Local\\Temp\\ipykernel_8064\\829510698.py:68: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "C:\\Users\\Nigam\\AppData\\Local\\Temp\\ipykernel_8064\\829510698.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['cluster'] = kmeans.fit_predict(df_cleaned[numerical_columns])\n",
      "C:\\Users\\Nigam\\AppData\\Local\\Temp\\ipykernel_8064\\829510698.py:80: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "C:\\Users\\Nigam\\anaconda3\\envs\\streamlit\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Nigam\\anaconda3\\envs\\streamlit\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Nigam\\anaconda3\\envs\\streamlit\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Nigam\\anaconda3\\envs\\streamlit\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Nigam\\anaconda3\\envs\\streamlit\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Nigam\\anaconda3\\envs\\streamlit\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-test: t-stat=-1.405435537292818, p-value=0.16058180851621773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nigam\\AppData\\Local\\Temp\\ipykernel_8064\\829510698.py:100: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.impute import SimpleImputer # Import SimpleImputer\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'amazon.csv'  # Replace with your file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Step 1: Handle Missing Values\n",
    "# Check for missing values in critical columns\n",
    "critical_columns = ['product_id', 'actual_price', 'discounted_price', 'rating', 'rating_count', 'category']\n",
    "print(\"Missing values before cleaning:\\n\", df[critical_columns].isnull().sum())\n",
    "\n",
    "\n",
    "# Drop rows with missing values in critical columns\n",
    "df_cleaned = df.dropna(subset=critical_columns)\n",
    "\n",
    "\n",
    "# Step 2: Normalize Numerical Data- # Data Cleaning and Preprocessing\n",
    "# Remove non-numeric characters and convert to float\n",
    "df_cleaned['actual_price'] = df_cleaned['actual_price'].str.replace('₹', '').str.replace(',', '').astype(float)\n",
    "df_cleaned['discounted_price'] = df_cleaned['discounted_price'].str.replace('₹', '').str.replace(',', '').astype(float)\n",
    "df_cleaned['rating'] = pd.to_numeric(df_cleaned['rating'], errors='coerce')\n",
    "df_cleaned['rating_count'] = df_cleaned['rating_count'].str.replace(',', '').astype(float)\n",
    "\n",
    "\n",
    "# Impute missing values in 'rating' column with the median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df_cleaned['rating'] = imputer.fit_transform(df_cleaned[['rating']])\n",
    "\n",
    "\n",
    "# Normalize numerical columns\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = ['actual_price', 'discounted_price', 'rating', 'rating_count']\n",
    "df_cleaned[numerical_columns] = scaler.fit_transform(df_cleaned[numerical_columns])\n",
    "\n",
    "\n",
    "# Step 3: Encode Categorical Features\n",
    "# Split categories and take the first as main category\n",
    "df_cleaned['main_category'] = df_cleaned['category'].str.split('|').str[0]\n",
    "\n",
    "\n",
    "# Encode the 'main_category' column\n",
    "encoder = LabelEncoder()\n",
    "df_cleaned['main_category_encoded'] = encoder.fit_transform(df_cleaned['main_category'])\n",
    "\n",
    "\n",
    "# Display the cleaned and normalized dataframe\n",
    "print(\"Cleaned Data Sample:\\n\", df_cleaned.head())\n",
    "\n",
    "\n",
    "# Data Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_cleaned['rating'], bins=20, kde=True)\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Feature Selection for Clustering\n",
    "features = ['discounted_price', 'actual_price', 'main_category_encoded', 'rating', 'rating_count']\n",
    "X = df_cleaned[features]\n",
    "\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "# Determine the optimal number of clusters using the Elbow Method\n",
    "inertia = []\n",
    "cluster_range = range(1, 11)\n",
    "for k in cluster_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cluster_range, inertia, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Elbow Method for Optimal Number of Clusters')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Apply K-Means Clustering\n",
    "optimal_clusters = 4  # Select based on the Elbow Method\n",
    "kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
    "df_cleaned['customer_segment'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Analyze clusters\n",
    "cluster_summary = df_cleaned.groupby('customer_segment')[features].mean()\n",
    "print(cluster_summary)\n",
    "\n",
    "# Visualize clusters\n",
    "sns.scatterplot(x='discounted_price', y='rating', hue='customer_segment', size='rating_count', data=df_cleaned)\n",
    "plt.title('Customer Segments')\n",
    "plt.show()\n",
    "\n",
    "# Visualize Customer Segments using PCA for Dimensionality Reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "df_cleaned['PCA1'] = X_pca[:, 0]\n",
    "df_cleaned['PCA2'] = X_pca[:, 1]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='PCA1', y='PCA2', hue='customer_segment', data=df_cleaned, palette='viridis')\n",
    "plt.title('Customer Segments Visualization using PCA')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.legend(title='Segment')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Analyze Customer Segments\n",
    "segment_analysis = df_cleaned.groupby('customer_segment')[features].mean()\n",
    "print(\"Customer Segment Analysis:\\n\", segment_analysis)\n",
    "\n",
    "\n",
    "# Visualize Customer Segment Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='customer_segment', data=df_cleaned, palette='viridis')\n",
    "plt.title('Customer Segment Distribution')\n",
    "plt.xlabel('Customer Segment')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Prepare Data for Association Rule Mining\n",
    "# Group products by transactions\n",
    "transactions = df_cleaned.groupby(['product_id', 'product_name'])['main_category'].apply(list).values.tolist()\n",
    "\n",
    "\n",
    "# One-hot encode the transactions\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(transactions).transform(transactions)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "\n",
    "# Apply Apriori Algorithm to find frequent itemsets\n",
    "min_support = 0.01  # Adjust this value based on your dataset\n",
    "frequent_itemsets = apriori(df_encoded, min_support=min_support, use_colnames=True)\n",
    "\n",
    "\n",
    "# Generate Association Rules\n",
    "min_confidence = 0.2  # Adjust this value as needed\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "\n",
    "\n",
    "# Sort rules by lift to find the most interesting ones\n",
    "rules = rules.sort_values(by='lift', ascending=False)\n",
    "\n",
    "\n",
    "# Display the top rules\n",
    "print(\"Top Association Rules:\")\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(10))\n",
    "\n",
    "\n",
    "# Visualize the Support, Confidence, and Lift of Top Rules\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(rules['support'], rules['confidence'], alpha=0.6, c=rules['lift'], cmap='viridis')\n",
    "plt.title('Association Rules: Support vs Confidence')\n",
    "plt.xlabel('Support')\n",
    "plt.ylabel('Confidence')\n",
    "plt.colorbar(label='Lift')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Decision Tree Classification Example\n",
    "X = df_cleaned[numerical_columns]\n",
    "y = df_cleaned['main_category_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Plot Decision Tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(clf, feature_names=numerical_columns, class_names=encoder.classes_, filled=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Statistical Analysis\n",
    "cat1 = df_cleaned[df_cleaned['main_category_encoded'] == 0]['rating']\n",
    "cat2 = df_cleaned[df_cleaned['main_category_encoded'] == 1]['rating']\n",
    "t_stat, p_val = ttest_ind(cat1, cat2, nan_policy='omit')\n",
    "print(f\"T-test: t-stat={t_stat}, p-value={p_val}\")\n",
    "\n",
    "\n",
    "# Calculate Discount Percentage\n",
    "df_cleaned['discount_percentage'] = ((df_cleaned['actual_price'] - df_cleaned['discounted_price']) / \n",
    "                                     df_cleaned['actual_price']) * 100\n",
    "\n",
    "\n",
    "# Step 1: Histograms and Box Plots for Prices\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df_cleaned['actual_price'], bins=30, kde=True, color='blue')\n",
    "plt.title('Distribution of Actual Prices')\n",
    "plt.xlabel('Actual Price')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df_cleaned['discounted_price'], bins=30, kde=True, color='green')\n",
    "plt.title('Distribution of Discounted Prices')\n",
    "plt.xlabel('Discounted Price')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=df_cleaned['actual_price'], color='blue')\n",
    "plt.title('Box Plot of Actual Prices')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=df_cleaned['discounted_price'], color='green')\n",
    "plt.title('Box Plot of Discounted Prices')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Step 2: Scatter Plots for Price Relationships\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='actual_price', y='discounted_price', data=df_cleaned, alpha=0.6)\n",
    "plt.title('Actual Price vs Discounted Price')\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Discounted Price')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='actual_price', y='discount_percentage', data=df_cleaned, alpha=0.6, color='red')\n",
    "plt.title('Actual Price vs Discount Percentage')\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Discount Percentage')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Step 3: Bar Charts for Rating Distribution and Popular Products\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='rating', data=df_cleaned, palette='viridis')\n",
    "plt.title('Product Rating Distribution')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_cleaned['rating_count'], bins=30, kde=True, color='purple')\n",
    "plt.title('Distribution of Rating Count')\n",
    "plt.xlabel('Rating Count')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Step 4: Bar Charts/Pie Charts for Category and Product Popularity\n",
    "category_counts = df_cleaned['main_category'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "category_counts.plot(kind='bar', color='orange')\n",
    "plt.title('Product Category Distribution')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "category_counts.plot(kind='pie', autopct='%1.1f%%', startangle=90, colors=sns.color_palette('pastel'))\n",
    "plt.title('Product Category Distribution (Pie Chart)')\n",
    "plt.ylabel('')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Step 5: Correlation Heatmap\n",
    "correlation_matrix = df_cleaned[['actual_price', 'discounted_price', 'rating', 'rating_count', 'discount_percentage']].corr()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Drop rows with missing values in user-related columns\n",
    "user_columns = ['user_id', 'user_name', 'review_title', 'review_content', 'rating_count']\n",
    "df_cleaned = df.dropna(subset=user_columns)\n",
    "\n",
    "# Drop rows with NaN rating_count\n",
    "df_cleaned = df_cleaned.dropna(subset=['rating_count'])  \n",
    "\n",
    "# Basic User Behavior Analysis\n",
    "# Top Users by Review Count\n",
    "top_users = df_cleaned['user_name'].value_counts().head(10)\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_users.plot(kind='bar', color='blue')\n",
    "plt.title('Top 10 Users by Review Count')\n",
    "plt.xlabel('User Name')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Rating Distribution Analysis\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_cleaned['rating_count'], bins=20, color='green', kde=True)\n",
    "plt.title('Distribution of Rating Count')\n",
    "plt.xlabel('Rating Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Sentiment Analysis on Review Content\n",
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "\n",
    "df_cleaned['sentiment'] = df_cleaned['review_content'].apply(get_sentiment)\n",
    "\n",
    "\n",
    "# Plot Sentiment Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_cleaned['sentiment'], bins=20, color='purple', kde=True)\n",
    "plt.title('Sentiment Distribution of Reviews')\n",
    "plt.xlabel('Sentiment Polarity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Word Cloud of Review Content\n",
    "review_text = ' '.join(df_cleaned['review_content'].astype(str).values)\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=STOPWORDS).generate(review_text)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.title('Word Cloud of Review Content')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Topic Modeling using Latent Dirichlet Allocation (LDA)\n",
    "vectorizer = CountVectorizer(max_df=0.9, min_df=2, stop_words='english')\n",
    "dtm = vectorizer.fit_transform(df_cleaned['review_content'].astype(str))\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(dtm)\n",
    "\n",
    "\n",
    "# Display the Top Words for each Topic\n",
    "num_words = 10\n",
    "words = vectorizer.get_feature_names_out()\n",
    "for i, topic in enumerate(lda.components_):\n",
    "    print(f\"\\nTopic {i+1}:\")\n",
    "    print([words[j] for j in topic.argsort()[-num_words:][::-1]])\n",
    "\n",
    "\n",
    "# Customer Segmentation based on Sentiment and Rating Count\n",
    "df_cleaned['sentiment_label'] = pd.cut(df_cleaned['sentiment'], bins=[-1, -0.01, 0.01, 1], labels=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='sentiment_label', data=df_cleaned, palette='viridis')\n",
    "plt.title('Customer Segments based on Sentiment')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Cross-tabulation of Rating Count and Sentiment\n",
    "rating_sentiment_crosstab = pd.crosstab(df_cleaned['rating_count'], df_cleaned['sentiment_label'])\n",
    "print(\"\\nRating Count vs Sentiment Analysis:\\n\", rating_sentiment_crosstab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f35515-b77a-4eac-81dd-169335b9c070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
